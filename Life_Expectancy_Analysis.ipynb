{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrXjdyXhRXsHu+O5DERQvM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surendran2566/Life_Expectancy_Analysis/blob/main/Life_Expectancy_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQk0bk_Cr_IT"
      },
      "outputs": [],
      "source": [
        "                                  ## üß† Project Title: Life Expectancy Analysis\n",
        "\n",
        "### üìÑ About the Dataset:\n",
        "'''\n",
        "This dataset represents key health and economic indicators from 193 countries spanning 2000‚Äì2015. Collected from WHO and UN sources,\n",
        "it includes features related to immunization, mortality, GDP, healthcare expenditure, schooling, and more.'''\n",
        "\n",
        "### üéØ Project Objective:\n",
        "\n",
        "'''We aim to determine which socio-economic and healthcare-related factors impact life expectancy the most, and how policies might help countries improve it.'''\n",
        "\n",
        "### üîç Key Research Questions:\n",
        "'''\n",
        "1. Which features truly impact life expectancy?\n",
        "2. Should low life expectancy countries (<65) increase healthcare expenditure?\n",
        "3. How do infant and adult mortality influence lifespan?\n",
        "4. Do lifestyle habits (e.g., alcohol, smoking, exercise) affect life expectancy?\n",
        "5. What‚Äôs the role of schooling on lifespan?\n",
        "6. Is alcohol consumption positively or negatively related?\n",
        "7. Does population density correlate with life expectancy?\n",
        "8. How does immunization affect longevity? '''\n",
        "\n",
        "############################################################################### üîß Step-by-Step Implementation\n",
        "\n",
        "### Step 1: Install and Import Required Libraries\n",
        "\n",
        "!pip install tensorflow keras keras-tuner shap scikit-learn seaborn xgboost\n",
        "!pip install nbstripout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "import shap\n",
        "import warnings\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
        "shap.initjs()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 2: Load and Inspect the Dataset\n",
        "\n",
        "from google.colab import files\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "# Upload your dataset (you'll get a pop-up to select the CSV file)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Load the first uploaded file safely\n",
        "df = pd.read_csv(io.BytesIO(next(iter(uploaded.values()))))\n",
        "\n",
        "# View the structure of the data\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nSample Data:\")\n",
        "print(df.head())\n",
        "print(\"\\nMissing Values Count:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "Fsv2SrhMtPd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 3: Data Cleaning\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "print(\"After Removing Nulls:\", df.shape)"
      ],
      "metadata": {
        "id": "jiQxhGEjtzlO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 4: Data Cleaning and Feature Engineering (Reshape Style)\n",
        "\n",
        "# Rename for consistency\n",
        "if 'Life expectancy' in df.columns:\n",
        "    df.rename(columns={'Life expectancy': 'Life_expectancy'}, inplace=True)\n",
        "\n",
        "# Ensure 'Year' is numeric\n",
        "df['Year'] = pd.to_numeric(df['Year'], errors='coerce')\n",
        "\n",
        "# Check and reassign Gender column if available\n",
        "if 'Gender' in df.columns:\n",
        "    reorder_cols = ['Country', 'Year', 'Gender'] + [col for col in df.columns if col not in ['Country', 'Year', 'Gender']]\n",
        "else:\n",
        "    reorder_cols = ['Country', 'Year'] + [col for col in df.columns if col not in ['Country', 'Year']]\n",
        "df = df[reorder_cols]\n",
        "\n",
        "# Remove non-numeric columns before imputation\n",
        "non_numeric_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
        "columns_to_impute = [col for col in df.columns if col not in ['Country', 'Year', 'Life_expectancy', 'Gender'] and col not in non_numeric_cols]\n",
        "\n",
        "# Impute missing values per country\n",
        "def groupwise_mean_impute(df, group_col, target_col):\n",
        "    return df.groupby(group_col)[target_col].transform(lambda x: pd.to_numeric(x, errors='coerce').fillna(x.mean()))\n",
        "\n",
        "for col in columns_to_impute:\n",
        "    df[col] = groupwise_mean_impute(df, 'Country', col)\n",
        "\n",
        "# Drop any remaining NaNs\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Summary outputs\n",
        "print(\"Cleaned Data Shape:\", df.shape)\n",
        "print(\"Duplicate Records:\", df.duplicated().sum())\n",
        "print(\"\\nDescriptive Statistics:\")\n",
        "display(df.describe())\n",
        "print(\"\\nNumber of Countries:\", df['Country'].nunique())\n",
        "print(\"Year Range:\", df['Year'].min(), \"-\", df['Year'].max())"
      ],
      "metadata": {
        "id": "5E8pnu38xG8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 5: Exploratory Data Analysis (EDA)\n",
        "\n",
        "                                # Dynamically drop columns based on availability\n",
        "drop_cols = ['Country', 'Year']\n",
        "if 'Life_expectancy' in df.columns:\n",
        "    drop_cols.append('Life_expectancy')\n",
        "elif 'Life expectancy' in df.columns:\n",
        "    drop_cols.append('Life expectancy')\n",
        "if 'Gender' in df.columns:\n",
        "    drop_cols.append('Gender')\n",
        "\n",
        "features = df.columns.drop(drop_cols)\n",
        "\n",
        "                    # Distribution plots\n",
        "for col in features:\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f\"Distribution: {col}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "                           # Correlation heatmap\n",
        "plt.figure(figsize=(14, 10))\n",
        "sns.heatmap(df.corr(numeric_only=True), cmap='coolwarm', annot=False)\n",
        "plt.title(\"Correlation Matrix\")\n",
        "plt.show()\n",
        "\n",
        "                                      # Gender vs Life Expectancy (if available)\n",
        "if 'Gender' in df.columns and 'Life_expectancy' in df.columns:\n",
        "    sns.boxplot(x='Gender', y='Life_expectancy', data=df)\n",
        "    plt.title(\"Life Expectancy by Gender\")\n",
        "    plt.show()\n",
        "elif 'Gender' in df.columns and 'Life expectancy' in df.columns:\n",
        "    sns.boxplot(x='Gender', y='Life expectancy', data=df)\n",
        "    plt.title(\"Life Expectancy by Gender\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "bSvkwvLOx3FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 6: Preprocessing ‚Äì Scaling & PCA\n",
        "\n",
        "# Identify numeric columns only\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "\n",
        "# Confirm actual column name for life expectancy\n",
        "target_column = 'Life expectancy '  # Note the space at the end\n",
        "\n",
        "# Exclude identifier and target columns\n",
        "exclude_cols = ['Country', 'Year', target_column]\n",
        "if 'Gender' in df.columns:\n",
        "    exclude_cols.append('Gender')\n",
        "\n",
        "features = [col for col in numeric_cols if col not in exclude_cols]\n",
        "\n",
        "# Define input and output\n",
        "X = df[features].copy()\n",
        "y = df[target_column].copy()\n",
        "\n",
        "# Standardize input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA to preserve 90% variance\n",
        "pca = PCA(n_components=0.9)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Output shapes\n",
        "print(\"Original numeric feature count:\", len(features))\n",
        "print(\"PCA reduced feature count:\", X_pca.shape[1])"
      ],
      "metadata": {
        "id": "o1RpX4KQ0-vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 7: Deep Learning Model\n",
        "\n",
        "def build_nn_model():\n",
        "    model = keras.Sequential([\n",
        "        keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(64, activation='relu'),\n",
        "        keras.layers.Dense(1)\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "nn_model = build_nn_model()\n",
        "nn_history = nn_model.fit(X_train, y_train, epochs=200, validation_split=0.2, verbose=0)\n",
        "\n",
        "plt.plot(nn_history.history['loss'], label='Train Loss')\n",
        "plt.plot(nn_history.history['val_loss'], label='Val Loss')\n",
        "plt.title('DL Model Loss History')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(\"Test MSE:\", nn_model.evaluate(X_test, y_test))"
      ],
      "metadata": {
        "id": "MWthCFIh1HsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 8: Classical ML Models + Evaluation\n",
        "\n",
        "X_train_ml, X_test_ml, y_train_ml, y_test_ml = train_test_split(X_scaled, y, test_size=0.3, random_state=42)\n",
        "\n",
        "models = {\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=42),\n",
        "    \"Extra Trees\": ExtraTreesRegressor(random_state=42),\n",
        "    \"Gradient Boost\": GradientBoostingRegressor(random_state=42),\n",
        "    \"XGBoost\": XGBRegressor(random_state=42)\n",
        "}\n",
        "\n",
        "results = []\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train_ml, y_train_ml)\n",
        "    preds = model.predict(X_test_ml)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test_ml, preds))\n",
        "    r2 = r2_score(y_test_ml, preds)\n",
        "    results.append((name, rmse, r2))\n",
        "\n",
        "results_df = pd.DataFrame(results, columns=['Model', 'RMSE', 'R2_Score']).sort_values(by='R2_Score', ascending=False)\n",
        "print(\"\\nModel Evaluation Results:\")\n",
        "print(results_df)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.barplot(x='Model', y='R2_Score', data=results_df)\n",
        "plt.title(\"Model Comparison - R2 Score\")\n",
        "plt.ylim(0.9, 1.0)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fFKUC40a3Z8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 9: Cross-Validation (XGBoost)\n",
        "\n",
        "best_model = XGBRegressor(random_state=42)\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(best_model, X_scaled, y, cv=kf, scoring='r2')\n",
        "\n",
        "print(\"\\nCross-Validation (XGBoost):\")\n",
        "print(f\"Mean R2 Score: {cv_scores.mean():.4f}\")\n",
        "print(f\"Standard Deviation: {cv_scores.std():.4f}\")\n",
        "\n",
        "plt.plot(cv_scores, marker='o')\n",
        "plt.title(\"Cross-Validation Scores\")\n",
        "plt.xlabel(\"Fold\")\n",
        "plt.ylabel(\"R2 Score\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IQI_GwNZ35ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 10: Feature Importance (Random Forest)\n",
        "\n",
        "rf = RandomForestRegressor(random_state=42)\n",
        "rf.fit(X_train_ml, y_train_ml)\n",
        "importances = rf.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(range(X.shape[1]), importances[indices])\n",
        "plt.xticks(range(X.shape[1]), np.array(features)[indices], rotation=90)\n",
        "plt.title(\"Feature Importances via Random Forest\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "giDicGmR4GZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Step 11: SHAP Value Interpretation (Neural Network)\n",
        "\n",
        "X_sample = X_train[:100]\n",
        "background = shap.kmeans(X_sample, 10)\n",
        "explainer = shap.KernelExplainer(nn_model.predict, background)\n",
        "shap_values = explainer.shap_values(X_sample)\n",
        "\n",
        "shap.summary_plot(shap_values[0], features=features)\n",
        "\n",
        "### ‚úÖ Conclusion:\n",
        "'''\n",
        "This notebook covers a complete life expectancy study.\n",
        "It includes data preprocessing, EDA, model training (deep learning and classical), evaluation, cross-validation, and interpretation.\n",
        "All steps align with the original project objectives, dataset documentation, and research questions.'''\n",
        "\n",
        " ##### THIS IS A WORK DONE BY 'SURENDRAN L'\n",
        "\n"
      ],
      "metadata": {
        "id": "0thnHyKl4OvL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}